from typing import Dict, List
from pydantic import BaseModel, Field
from semantic_kernel.kernel import Kernel
from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion
import asyncio
import json


# === Pydantic Output Model for Section Review ===
class SectionReview(BaseModel):
    sections: Dict[str, bool] = Field(..., description="Mapping of section names to True (needs edit) or False (no change)")


# === Main Assistant Class ===
class LLMContentAssistant:
    def __init__(self, openai_api_key: str, model: str = "gpt-4"):
        self.kernel = Kernel()
        self.kernel.add_chat_service(
            "openai",
            OpenAIChatCompletion(model=model, api_key=openai_api_key)
        )

    async def classify_sections(self, user_instruction: str, sectioned_text: str) -> SectionReview:
        prompt = f"""
You are a content reviewer assistant.

Your job is to analyze the user's instruction and compare it with the current content to determine which section(s) need to be edited.

--- USER INSTRUCTION ---
{user_instruction}

--- EXISTING TEXT SECTIONS ---
{sectioned_text}

INSTRUCTIONS:
1. For each section, return `true` if the section needs to be changed, and `false` if it can remain as is.
2. Return only valid JSON in the format:
{{
  "Section Name": true,
  "Another Section": false
}}

DO NOT include any explanation or text other than the JSON.
"""
        result = await self.kernel.chat_service.complete(prompt)
        parsed = SectionReview(sections=json.loads(result.strip()))
        return parsed

    async def generate_search_terms(self, user_query: str) -> List[str]:
        prompt = f"""
You are an intelligent assistant designed to extract **relevant search terms** from a user query.

--- USER QUERY ---
{user_query}

INSTRUCTIONS:
1. Identify key concepts, actions, or topics.
2. Return only the most relevant terms as a JSON array:

FORMAT:
[
  "search term 1",
  "search term 2"
]

Do NOT include explanations or extra text.
"""
        result = await self.kernel.chat_service.complete(prompt)
        return json.loads(result.strip())

    async def requires_additional_context(self, user_prompt: str, existing_output: str) -> bool:
        prompt = f"""
You are an expert assistant.

Determine if the user's prompt requires new or external context beyond the provided content.

--- USER PROMPT ---
{user_prompt}

--- EXISTING OUTPUT ---
{existing_output}

RULES:
- Return `false` if the request is to reword, summarize, reformat, simplify, or delete parts.
- Return `true` if it asks for new info, comparisons, external facts, or any missing content.

Respond only with `true` or `false`.
"""
        result = await self.kernel.chat_service.complete(prompt)
        return result.strip().lower() == "true"

    async def extract_bulleted_sections_llm(self, raw_text: str) -> Dict[str, Dict[str, List[str]]]:
        prompt = f"""
You are a parser that converts text with subsections and bullet points into structured JSON.

--- INPUT TEXT ---
{raw_text}

RULES:
- Subsections start with '### Section Name -'.
- Bullet points start with '-'.
- Extract each section name and all bullets under it.

FORMAT:
{{
  "Section Name": {{
    "bullets": [
      "bullet 1",
      "bullet 2"
    ]
  }},
  ...
}}

Return only the valid JSON object. Do not include any explanation or text.
"""
        result = await self.kernel.chat_service.complete(prompt)
        return json.loads(result.strip())


# === Example Test Runner ===
if __name__ == "__main__":
    async def main():
        # Replace with your actual OpenAI key
        assistant = LLMContentAssistant(openai_api_key="your-openai-api-key")

        # 1. Classify sections
        user_instruction = "Update client overview and next best action."
        sectioned_text = """
        {
            "Client Overview": "Client has 3 segments: A, B, and C.",
            "Next Best Action": "Suggest product placement.",
            "Opportunities": "Strong growth in East market."
        }
        """
        section_result = await assistant.classify_sections(user_instruction, sectioned_text)
        print("\nüß© Section Classification:\n", section_result.json(indent=2))

        # 2. Generate search terms
        query = "Insights on quarterly sales trends in the healthcare sector"
        search_terms = await assistant.generate_search_terms(query)
        print("\nüîç Search Terms:\n", search_terms)

        # 3. Check if user query needs new context
        user_prompt = "Add a comparison with competitor performance"
        existing_output = "The client revenue grew by 15% in Q2."
        needs_context = await assistant.requires_additional_context(user_prompt, existing_output)
        print("\nüìå Needs Additional Context?:", needs_context)

        # 4. Extract sections and bullets from LLM
        raw_text = """
        ### Risks- 
        - Market volatility may impact returns.
        - Regulatory changes are expected.

        ### Opportunities-
        - Expand into new regions.
        - Launch a digital product line.
        """
        bullets_json = await assistant.extract_bulleted_sections_llm(raw_text)
        print("\nüìë Bulleted Sections JSON:\n", json.dumps(bullets_json, indent=2))

    asyncio.run(main())
