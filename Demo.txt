import json
from guardrails import Guard
from guardrails.hub import ValidJson
from openai import AzureOpenAI
import os

# Azure setup
os.environ["AZURE_OPENAI_API_KEY"] = "<KEY>"
os.environ["AZURE_OPENAI_ENDPOINT"] = "<ENDPOINT>"
client = AzureOpenAI(...)

rail_spec = """..."""  # include valid_json checkpoint

guard = Guard.for_rail_string(rail_spec).use(ValidJson, on_fail="reask")

def azure_llm(*, messages, **kwargs) -> str:
    resp = client.chat.completions.create(
      model=kwargs["model"],
      messages=messages,
      ...
    )
    return resp.choices[0].message.content

raw, validated, *rest = guard(
    azure_llm,
    messages=[{"role":"user","content":"Your prompt"}],
    model="gpt-4o",
    temperature=0.7,
)

# Now it's valid JSON â€” parse it
parsed = json.loads(validated["response"])
print(parsed)
