"""
LinkedIn Profile Scraper - A modular and maintainable implementation
"""

import os
import time
import pickle
import logging
from typing import List, Optional, Iterator

from bs4 import BeautifulSoup
from googlesearch import search
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service


# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('linkedin_scraper.log')
    ]
)
logger = logging.getLogger('linkedin_scraper')


class ConfigManager:
    """Manages configuration settings for the LinkedIn scraper."""
    
    def __init__(self, 
                 driver_path: str = None, 
                 cookie_path: str = None,
                 skip_keywords: List[str] = None):
        """
        Initialize the ConfigManager with paths and settings.
        
        Args:
            driver_path: Path to the ChromeDriver executable
            cookie_path: Path to store/retrieve cookies
            skip_keywords: List of keywords to skip in profile text
        """
        self.driver_path = driver_path or os.path.join(os.getcwd(), "chromedriver.exe")
        self.cookie_path = cookie_path or os.path.join(os.getcwd(), "linkedin_cookies.pkl")
        self.skip_keywords = skip_keywords or [
            "mutual connection", 
            "Status is offline", 
            "degree connection", 
            "mutual connection"
        ]
        
    def validate(self) -> bool:
        """
        Validate that the configuration is correct.
        
        Returns:
            bool: True if configuration is valid, False otherwise
        """
        if not os.path.exists(self.driver_path):
            logger.error(f"ChromeDriver not found at: {self.driver_path}")
            return False
        
        return True


class LinkedInAuthManager:
    """Manages authentication with LinkedIn."""
    
    def __init__(self, config: ConfigManager):
        """
        Initialize the authentication manager.
        
        Args:
            config: ConfigManager instance with configuration settings
        """
        self.config = config
    
    def save_cookies_after_manual_login(self, login_wait_time: int = 90) -> bool:
        """
        Opens a browser for manual login and saves cookies.
        
        Args:
            login_wait_time: Time in seconds to wait for manual login
            
        Returns:
            bool: True if successful, False otherwise
        """
        try:
            service = Service(executable_path=self.config.driver_path)
            driver = webdriver.Chrome(service=service)
            driver.get("https://www.linkedin.com/login")
            
            logger.info("Please log in manually within the browser window...")
            time.sleep(login_wait_time)
            
            with open(self.config.cookie_path, "wb") as file:
                pickle.dump(driver.get_cookies(), file)
            
            logger.info("Cookies saved successfully.")
            driver.quit()
            return True
            
        except Exception as e:
            logger.error(f"Error during manual login: {str(e)}")
            return False
    
    def load_cookies(self, driver) -> bool:
        """
        Load cookies from file into the driver.
        
        Args:
            driver: WebDriver instance
            
        Returns:
            bool: True if successful, False otherwise
        """
        try:
            if not os.path.exists(self.config.cookie_path):
                logger.error(f"Cookie file not found: {self.config.cookie_path}")
                return False
                
            driver.get("https://www.linkedin.com")
            with open(self.config.cookie_path, "rb") as f:
                cookies = pickle.load(f)
                
            for cookie in cookies:
                if 'sameSite' in cookie:
                    del cookie['sameSite']
                driver.add_cookie(cookie)
                
            driver.get("https://www.linkedin.com/feed/")
            time.sleep(1)
            
            if "Sign In" in driver.title or "Log In" in driver.title:
                logger.error("Authentication failed: Cookies are not valid.")
                return False
                
            return True
            
        except Exception as e:
            logger.error(f"Error loading cookies: {str(e)}")
            return False


class LinkedInSearcher:
    """Handles searching for LinkedIn profiles."""
    
    @staticmethod
    def search_profiles(query: str, num_results: int = 1) -> Iterator[str]:
        """
        Search for LinkedIn profiles using Google.
        
        Args:
            query: Search query string
            num_results: Number of results to return
            
        Returns:
            Iterator of URLs
        """
        try:
            search_results = search(query, num_results=num_results)
            return search_results
        except Exception as e:
            logger.error(f"Error searching profiles: {str(e)}")
            return iter([])


class ProfileScraper:
    """Scrapes LinkedIn profiles."""
    
    def __init__(self, config: ConfigManager, auth_manager: LinkedInAuthManager):
        """
        Initialize the profile scraper.
        
        Args:
            config: ConfigManager instance
            auth_manager: LinkedInAuthManager instance
        """
        self.config = config
        self.auth_manager = auth_manager
    
    def scrape_profile(self, url: str, text_to_terminate_profile_append: str = None) -> Optional[str]:
        """
        Scrape a LinkedIn profile.
        
        Args:
            url: LinkedIn profile URL
            text_to_terminate_profile_append: Text that signals end of profile content
            
        Returns:
            str: Extracted profile text or None if failed
        """
        driver = None
        try:
            chrome_options = Options()
            # Uncomment for headless mode in production
            # chrome_options.add_argument("--headless")
            chrome_options.add_argument("--no-sandbox")
            chrome_options.add_argument("--disable-dev-shm-usage")
            
            service = Service(self.config.driver_path)
            driver = webdriver.Chrome(service=service, options=chrome_options)
            
            # Load cookies for authentication
            if not self.auth_manager.load_cookies(driver):
                return None
            
            # Go to the LinkedIn profile
            logger.info(f"Accessing profile: {url}")
            driver.get(url)
            time.sleep(2)
            
            # Extract content
            html_content = driver.page_source
            extracted_text = self._parse_profile_content(
                html_content, 
                self.config.skip_keywords,
                text_to_terminate_profile_append
            )
            
            return extracted_text
            
        except Exception as e:
            logger.error(f"Error scraping profile: {str(e)}")
            return None
            
        finally:
            if driver:
                driver.quit()
    
    def _parse_profile_content(self, 
                              html_content: str, 
                              skip_keywords: List[str],
                              text_to_terminate_profile_append: str) -> str:
        """
        Parse HTML content to extract profile information.
        
        Args:
            html_content: HTML content of the profile page
            skip_keywords: Keywords to skip
            text_to_terminate_profile_append: Text to stop parsing at
            
        Returns:
            str: Extracted profile text
        """
        soup = BeautifulSoup(html_content, 'html.parser')
        spans = soup.find_all('span', class_='visually-hidden')
        
        extracted_lines = []
        for span in spans:
            text = span.get_text(strip=True)
            
            if not text:
                continue
                
            if any(skip_kw.lower() in text.lower() for skip_kw in skip_keywords):
                continue
                
            if text_to_terminate_profile_append and text == text_to_terminate_profile_append:
                break
                
            extracted_lines.append(text)
            
        return "\n".join(extracted_lines)


class LinkedInProfileFetcher:
    """Main class orchestrating the LinkedIn profile fetching process."""
    
    def __init__(self,
                driver_path: str = None,
                cookie_path: str = None,
                skip_keywords: List[str] = None):
        """
        Initialize the profile fetcher with configuration.
        
        Args:
            driver_path: Path to ChromeDriver
            cookie_path: Path to cookies file
            skip_keywords: Keywords to skip in profile text
        """
        self.config = ConfigManager(
            driver_path=driver_path,
            cookie_path=cookie_path,
            skip_keywords=skip_keywords
        )
        
        if not self.config.validate():
            raise ValueError("Invalid configuration")
            
        self.auth_manager = LinkedInAuthManager(self.config)
        self.searcher = LinkedInSearcher()
        self.scraper = ProfileScraper(self.config, self.auth_manager)
    
    def setup_authentication(self, login_wait_time: int = 90) -> bool:
        """
        Set up authentication by manually logging in.
        
        Args:
            login_wait_time: Time in seconds to wait for manual login
            
        Returns:
            bool: True if successful, False otherwise
        """
        return self.auth_manager.save_cookies_after_manual_login(login_wait_time)
    
    def get_profile(self, 
                   name: str, 
                   company: str, 
                   text_to_terminate_profile_append: str = None) -> Optional[str]:
        """
        Get a LinkedIn profile by name and company.
        
        Args:
            name: Person's name
            company: Company name
            text_to_terminate_profile_append: Text to stop parsing at
            
        Returns:
            str: Profile data or None if failed
        """
        query = f"{name} {company} site:linkedin.com"
        query_text = f"Name: {name} Company: {company}\n"
        
        try:
            # Search for the profile
            results = self.searcher.search_profiles(query=query, num_results=1)
            url = next(results, None)
            
            if not url:
                logger.error("No profile found for the search query")
                return f"{query_text}Profile Data: Not found"
            
            # Scrape the profile
            profile_data = self.scraper.scrape_profile(
                url, 
                text_to_terminate_profile_append
            )
            
            if profile_data:
                return f"{query_text}Profile Data:\n{profile_data}"
            else:
                return f"{query_text}Profile Data: Failed to scrape"
                
        except Exception as e:
            logger.error(f"Error getting profile: {str(e)}")
            return f"{query_text}Profile Data: Error - {str(e)}"


# Example usage
if __name__ == "__main__":
    # Create the profile fetcher
    fetcher = LinkedInProfileFetcher()
    
    # First-time setup - only needed once
    # fetcher.setup_authentication(login_wait_time=90)
    
    # Get a profile
    profile_data = fetcher.get_profile(
        name="John Doe",
        company="Acme Inc"
    )
    
    print(profile_data)
